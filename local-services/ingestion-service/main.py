import os
from typing import List

from fastapi import FastAPI, Request
from gcp import PubSubService
from models import Event
from utils import DataFormatter, FileHandler

PROJECT_ID = os.environ["PROJECT_ID"]
EVENTS_TOPIC_ID = os.environ["EVENTS_TOPIC_ID"]
STATUS_TOPIC_ID = os.environ["STATUS_TOPIC_ID"]
CSV_PROCESSED_FOLDER = os.environ["CSV_PROCESSED_FOLDER"]

app = FastAPI()
events_publisher = PubSubService(project_id=PROJECT_ID, topic_id=EVENTS_TOPIC_ID)
status_publisher = PubSubService(project_id=PROJECT_ID, topic_id=STATUS_TOPIC_ID)


@app.get("/")
def read_root():
    return {"Hello": "World"}


@app.post("/ingest")
def ingest(events: List[Event]):
    """
    Ingests a list of event data, formats it, and initiates the ingestion process.

    This endpoint accepts a list of `Event` objects, processes each event to the
    required data format, and then publishes both the data and ingestion status
    using dedicated publishers. The function returns a success message and the
    ingestion status, indicating that the backend ingestion job has been successfully
    created.

    Args:
        events (List[Event]): A list of event data objects to be ingested.

    Returns:
        dict: A dictionary containing:
            - "message" (str): Confirmation message for the ingestion job.
            - `status` (dict): Status details about the ingestion process, as
              generated by the `DataFormatter`.

    Note:
        A notification will be sent to the #ingestion-jobs Slack channel upon
        completion of the ingestion process.
    """

    formatter = DataFormatter()
    data = list(formatter.from_pydantic(data=events))
    status = formatter.generate_ingestion_status(data)

    events_publisher.send(data)
    status_publisher.send(status)

    return {
        "message": (
            "The Ingestion Job was successfully created at backend side. "
            "A notification will be sent to #ingestion-jobs slack channel as soon as "
            "the ingestion finishes."
        ),
        **status,
    }


@app.get("/ingest/dir/{directory}/file/{file_name}")
def ingest_csv_file(request: Request, directory: str, file_name: str):
    """
    Ingests data from a specified CSV file, processes it, and initiates the ingestion process.

    This endpoint retrieves and processes a CSV file specified by `directory` and `file_name`.
    The file data is formatted, ingested, and the ingestion status is published. Upon successful
    ingestion, the file is moved to a designated "processed" folder.

    Args:
        request (Request): The HTTP request object containing headers with metadata.
            - "has_header" (str): A header specifying if the CSV file includes a header row
              (1 for True, 0 for False).
        directory (str): The directory where the CSV file is located.
        file_name (str): The name of the CSV file to be ingested.

    Returns:
        dict: A dictionary containing:
            - "message" (str): Confirmation message for the ingestion job and file move.
            - `status` (dict): Status details about the ingestion process, as generated by
              the `DataFormatter`.
    """

    formatter = DataFormatter()
    file_handler = FileHandler(dir=directory)
    file_has_header = bool(int(request.headers.get("has_header")))

    try:
        data = [
            formatter.from_csv(line)
            for line in file_handler.read_csv(
                file=file_name, has_header=file_has_header
            )
        ]

        status = formatter.generate_ingestion_status(data)

        events_publisher.send(data)
        status_publisher.send(status)

        file_handler.move_file(file_name, processed_folder=CSV_PROCESSED_FOLDER)

        return {
            "message": (
                "The Ingestion Job was successfully created at backend side. "
                "A notification will be sent to #ingestion-jobs slack channel as soon as "
                "the ingestion finishes. "
                "Files were moved to processed folder."
            ),
            **status,
        }
    except FileNotFoundError:
        return {f"Either file {file_name} or directory {directory} were not found."}


@app.get("/ingest/dir/{directory}")
def ingest_csv_files(request: Request, directory: str):
    """
    Ingests data from all CSV files in a specified directory, processes the data, and initiates the ingestion process.

    This endpoint reads all CSV files found in the specified `directory`, formats their data, and publishes
    both the data and ingestion status. After successful ingestion, the files are moved to a designated
    "processed" folder.

    Args:
        request (Request): The HTTP request object containing headers with metadata.
            - "has_header" (str): A header specifying if the CSV files include header rows
              (1 for True, 0 for False).
        directory (str): The directory from which CSV files are read.

    Returns:
        dict: A dictionary containing:
            - "message" (str): Confirmation message indicating ingestion job creation and file movement.
            - `status` (dict): Status details about the ingestion process, generated by `DataFormatter`.

    Side Effects:
        - Reads and formats data from all CSV files in the specified directory.
        - Sends formatted data and ingestion status to publishers (`events_publisher` and `status_publisher`).
        - Moves all processed files to the `CSV_PROCESSED_FOLDER`.

    Notes:
        - Returns a message if no files are found in the directory.
        - A notification is sent to the #ingestion-jobs Slack channel upon ingestion completion.
        - Processed files are moved to a dedicated folder after successful ingestion.
    """

    formatter = DataFormatter()
    file_handler = FileHandler(dir=directory)
    file_has_header = bool(int(request.headers.get("has_header") or 0))

    files = list(file_handler.list_files())

    if len(files) == 0:
        return f"No files were found under directory {directory}"

    data = [
        formatter.from_csv(line)
        for file in files
        for line in file_handler.read_csv(file=file, has_header=file_has_header)
    ]

    status = formatter.generate_ingestion_status(data)

    events_publisher.send(data)
    status_publisher.send(status)

    file_handler.move_files(files, processed_folder=CSV_PROCESSED_FOLDER)

    return {
        "message": (
            "The Ingestion Job was successfully created at backend side. "
            "A notification will be sent to #ingestion-jobs slack channel as soon as "
            "the ingestion finishes. "
            "Files were moved to processed folder."
        ),
        **status,
    }
